{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMhHWHQZFJ1TWe9s+VbNri"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gv6my4KDr0j"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_YOLOdata(src_path, set='train', n_samples=None):\n",
        "  '''Loads images and labels from folder containing subfolders of 'images' and 'labels' (YOLO format).\n",
        "  Args:\n",
        "  src_path (Path): Path to source folder.\n",
        "  set (str): Set to be loaded. Either 'train' or 'val'.\n",
        "  n_samples (int): Number of image samples to load. If None, load all images and their associated labels.\n",
        "  Return:\n",
        "  images: List of images, type ndarray.\n",
        "  labels: List of labels, type ndarray.\n",
        "  '''\n",
        "  images, labels = [], []\n",
        "\n",
        "  # fetch images and labels files\n",
        "  img_dir = src_path / set / 'images'\n",
        "  label_dir = src_path / set / 'labels'\n",
        "  img_files = list(img_dir.glob('*.jpg'))\n",
        "  label_files = list(label_dir.glob('*.txt'))\n",
        "\n",
        "  # each image should be matched up with a label\n",
        "  assert len(img_files) == len(label_files)\n",
        "\n",
        "  # take n random samples from dataset\n",
        "  if n_samples:\n",
        "    sample_idx = np.random.choice(len(img_files), n_samples, replace=False)\n",
        "    img_files = [img_files[i] for i in sample_idx]\n",
        "    label_files = [label_files[i] for i in sample_idx]\n",
        "\n",
        "  for img_file in img_files:\n",
        "    img = cv2.imread(str(img_file)) # cv2 loads image in BGR\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # convert to RGB\n",
        "    images.append(img)\n",
        "\n",
        "  # YOLO labels as <class_id> <x_center> <y_center> <box_width> <box_height>\n",
        "  # the values are normalized between 0 and 1, propotional to image size\n",
        "  for label_file in label_files:\n",
        "    with open(str(label_file), 'r') as f:\n",
        "      # each line is a bounding box label\n",
        "      lines = f.readlines()\n",
        "      label = [line.strip().split() for line in lines]\n",
        "      label = np.array(label, dtype=np.float32)\n",
        "      labels.append(label)\n",
        "\n",
        "  return images, labels"
      ],
      "metadata": {
        "id": "aQPVaXebEP7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create custom pytorch dataset\n",
        "class YOLOdataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx]\n",
        "        label = torch.from_numpy(self.labels[idx]).float()\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        else:\n",
        "            img = cv2.resize(img, (224,224))\n",
        "            img = transforms.ToTensor()(img)\n",
        "            img = transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    # needed since pytorch cannot 'auto-batch' images with varying number of bounding boxes, labels have\n",
        "    # different tensor sizes -> so instead of torch.stack that pytorch would do automatically, we leave labels as a list of tensors\n",
        "    def custom_collate_fn(self, batch):\n",
        "        images, labels = zip(*batch) # unpack batch\n",
        "        images = torch.stack(images)\n",
        "        return images, labels\n",
        "\n",
        "\n",
        "# DataLoaders\n",
        "def get_loader(src_path, set='train', n_samples=None, batch_size=4, shuffle=True):\n",
        "    images, labels = get_YOLOdata(src_path, set=set, n_samples=n_samples) # get data from src\n",
        "\n",
        "    dataset = YOLOdataset(images, labels) # make pytorch dataset\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=dataset.custom_collate_fn) # make dataloader (with pytorch dataset)\n",
        "    return loader"
      ],
      "metadata": {
        "id": "iCvB1u-0lduk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_path = Path(r\"C:\\Users\\emman\\OneDrive\\Documents\\MI Projects\\Hot Dog Detection YOLO\")"
      ],
      "metadata": {
        "id": "fnAOM-xeLtSG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}